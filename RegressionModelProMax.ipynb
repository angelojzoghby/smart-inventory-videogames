{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvSVWJW_o79G",
        "outputId": "e48960e7-4f83-43ce-a6de-8249b9e74e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Data loaded successfully.\n",
            "Shape: (304, 7)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, make_scorer\n",
        "\n",
        "# Load the new CSV file\n",
        "df = pd.read_csv(\"SelectedGamesAdjustedData.csv\")\n",
        "\n",
        "print(\"New Data loaded successfully.\")\n",
        "print(f\"Shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Base Price Feature Engineering (Using the highly important 'Title' column) ---\n",
        "\n",
        "# Calculate the median price for each game title when it is NOT on discount.\n",
        "# This serves as the 'base retail price' of the game.\n",
        "base_price_map = df[df['Is on Discount (1/0)'] == 0].groupby('Title')['Price (USD)'].median()\n",
        "\n",
        "# Fallback: If a game only has discounted entries, use the overall median price of the game.\n",
        "# This prevents NaN values.\n",
        "base_price_map = base_price_map.combine_first(df.groupby('Title')['Price (USD)'].median())\n",
        "\n",
        "# Map the calculated base price back to the main DataFrame\n",
        "df['Base_Price'] = df['Title'].map(base_price_map)\n",
        "\n",
        "\n",
        "# --- 2. Genre Feature Engineering ---\n",
        "\n",
        "# Function to clean and parse the string representation of a list\n",
        "def parse_list_string(list_string):\n",
        "    if pd.isna(list_string):\n",
        "        return []\n",
        "    matches = re.findall(r\"'(.*?)'\", list_string)\n",
        "    return [match.strip() for match in matches if match.strip()]\n",
        "\n",
        "# Apply the parsing function\n",
        "df['Genres'] = df['Genres'].apply(parse_list_string)\n",
        "\n",
        "# Use MultiLabelBinarizer for the Genres column\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_matrix = mlb.fit_transform(df['Genres'])\n",
        "genre_df = pd.DataFrame(genre_matrix, columns=[f'Genre_{c}' for c in mlb.classes_])\n",
        "\n",
        "# Merge the new genre features and Base_Price, and drop the originals\n",
        "df_processed = pd.concat([df.drop(columns=['Genres', 'Title']).reset_index(drop=True), genre_df], axis=1)\n",
        "\n",
        "print(\"Feature engineering complete. Base_Price added and Genres binarized.\")\n",
        "print(df_processed[['Base_Price', 'Price (USD)']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lR0DTuMo-m3",
        "outputId": "d0535cc0-32ba-4cbb-8d80-6c4cbca7e201"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature engineering complete. Base_Price added and Genres binarized.\n",
            "   Base_Price  Price (USD)\n",
            "0      20.615        24.99\n",
            "1      20.615        10.00\n",
            "2      20.615        14.99\n",
            "3      20.615         2.50\n",
            "4      20.615        18.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define Target Variable (y)\n",
        "y = df_processed['Price (USD)']\n",
        "\n",
        "# 2. Define Features (X) - All columns except the target\n",
        "X = df_processed.drop(columns=['Price (USD)'])\n",
        "\n",
        "# 3. Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"Features used (including Base_Price and Genres): {X_train.columns.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqB9KFYvpBfh",
        "outputId": "ea8fefb8-5f01-4b2c-ee69-d1fb1ee7baab"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (243, 10)\n",
            "Features used (including Base_Price and Genres): ['Has DLC (1/0)', 'Is F2P (1/0)', 'Is on Game Pass (1/0)', 'Is on Discount (1/0)', 'Base_Price', 'Genre_Adventure', 'Genre_Brawler', 'Genre_Platform', 'Genre_RPG', 'Genre_Strategy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Random Forest Regressor model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Create a simple pipeline\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('regressor', rf_model)\n",
        "])\n",
        "\n",
        "# Train the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the initial model\n",
        "y_pred_initial = pipeline.predict(X_test)\n",
        "mae_initial = mean_absolute_error(y_test, y_pred_initial)\n",
        "r2_initial = r2_score(y_test, y_pred_initial)\n",
        "\n",
        "print(f\"--- Initial Model Evaluation with Base_Price Feature ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_initial:.2f}\")\n",
        "print(f\"R-squared (R2) Score: {r2_initial:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml3eQaUXpFzg",
        "outputId": "cda15d30-a1aa-4acc-aa26-21600ef3595e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initial Model Evaluation with Base_Price Feature ---\n",
            "Mean Absolute Error (MAE): $1.28\n",
            "R-squared (R2) Score: 0.9914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [100, 200, 300],\n",
        "    'regressor__max_depth': [5, 10, 15, None],\n",
        "    'regressor__min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "# Use MAE as the scoring metric (we want to minimize it)\n",
        "# We use 'neg_mean_absolute_error' because GridSearchCV always maximizes the score.\n",
        "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
        "\n",
        "# Setup GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=5, # 5-fold cross-validation\n",
        "    scoring=mae_scorer,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Starting Hyperparameter Tuning...\")\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# The best estimator found by the search\n",
        "best_pipeline = grid_search.best_estimator_\n",
        "\n",
        "print(\"\\n--- Tuning Complete ---\")\n",
        "print(f\"Best Parameters found: {grid_search.best_params_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcdWB4jOpIOZ",
        "outputId": "b9b0cb0d-ee27-4150-be30-5ba77a4fcc97"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Hyperparameter Tuning...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "\n",
            "--- Tuning Complete ---\n",
            "Best Parameters found: {'regressor__max_depth': None, 'regressor__min_samples_split': 2, 'regressor__n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using the best tuned model\n",
        "y_pred_tuned = best_pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the final model\n",
        "mae_final = mean_absolute_error(y_test, y_pred_tuned)\n",
        "r2_final = r2_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"--- Final Tuned Model Evaluation ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_final:.2f}\")\n",
        "print(f\"R-squared (R2) Score: {r2_final:.4f}\")\n",
        "\n",
        "# Check against the targets\n",
        "if mae_final < 4 and r2_final > 0.8:\n",
        "    print(\"\\n✅ SUCCESS: Model meets both target criteria!\")\n",
        "else:\n",
        "    print(\"\\n❌ NOTE: Model did not meet both target criteria. Consider adding more base game data or exploring Gradient Boosting models.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf5sqsxopLg3",
        "outputId": "434bac0e-6e27-4cd5-ab69-0fd2c824f0cb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Final Tuned Model Evaluation ---\n",
            "Mean Absolute Error (MAE): $1.28\n",
            "R-squared (R2) Score: 0.9911\n",
            "\n",
            "✅ SUCCESS: Model meets both target criteria!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6y1tSOANpOLv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}